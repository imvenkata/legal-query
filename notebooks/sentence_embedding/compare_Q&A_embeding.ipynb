{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c143a4123db24944bbd3ff909422ac4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a1d1b57085461482e89b0ca31b3f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c33b57d903c4849bedaca0e996156dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f242071f21340be989299640c7e9375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fabbb191d64407b538b9ed3d1cfe39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 768)\n",
      "tensor([[1.0000, 0.8051],\n",
      "        [0.8051, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"nlpaueb/legal-bert-base-uncased\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"Who are the parties to the Agreement and what are their defined names?\",\n",
    "    \"Cloud Investments Ltd. (“Company”) and Jack Robinson (“Advisor”)\",\n",
    "]\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hilla/code/10Academy-training/week11/contract-qa-high-precision-rag/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 768)\n",
      "tensor([[1.0000, 0.8051],\n",
      "        [0.8051, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"nlpaueb/legal-bert-base-uncased\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"Who are the parties to the Agreement and what are their defined names?\",\n",
    "    \"Cloud Investments Ltd. (“Company”) and Jack Robinson (“Advisor”)\",\n",
    "]\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../../\")\n",
    "\n",
    "from src.utils import extract_qa_pairs_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_qa_pairs_to_df(\"data/evaluation_sets/Robinson_Q&A.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who are the parties to the Agreement and what ...</td>\n",
       "      <td>Cloud Investments Ltd. (“Company”) and Jack Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the termination notice?</td>\n",
       "      <td>According to section 4:14 days for convenience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the payments to the Advisor under the...</td>\n",
       "      <td>According to section 6: 1. Fees of $9 per hour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can the Agreement or any of its obligations be...</td>\n",
       "      <td>1. Under section 1.1 the Advisor can’t assign ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who owns the IP?</td>\n",
       "      <td>According to section 4 of the Undertaking (App...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Who are the parties to the Agreement and what ...   \n",
       "1                    What is the termination notice?   \n",
       "2  What are the payments to the Advisor under the...   \n",
       "3  Can the Agreement or any of its obligations be...   \n",
       "4                                  Who owns the IP?    \n",
       "\n",
       "                                       ground_truths  \n",
       "0  Cloud Investments Ltd. (“Company”) and Jack Ro...  \n",
       "1  According to section 4:14 days for convenience...  \n",
       "2  According to section 6: 1. Fees of $9 per hour...  \n",
       "3  1. Under section 1.1 the Advisor can’t assign ...  \n",
       "4  According to section 4 of the Undertaking (App...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Pair: ['Who are the parties to the Agreement and what are their defined names?', 'Cloud Investments Ltd. (“Company”) and Jack Robinson (“Advisor”)\\n']\n",
      "Similarity: 0.8050569295883179\n",
      "Sentence Pair: ['What is the termination notice?', 'According to section 4:14 days for convenience by both parties. The Company may terminate without notice if the Advisor refuses or cannot perform the Services or is in breach of any provision of this Agreement.  \\n']\n",
      "Similarity: 0.7069092988967896\n",
      "Sentence Pair: ['What are the payments to the Advisor under the Agreement? ', 'According to section 6: 1. Fees of $9 per hour up to a monthly limit of $1,500, 2. Workspace expense of $100 per month, 3. Other reasonable and actual expenses if approved by the company in writing and in advance.\\n']\n",
      "Similarity: 0.827538013458252\n",
      "Sentence Pair: ['Can the Agreement or any of its obligations be assigned?', '1. Under section 1.1 the Advisor can’t assign any of his obligations without the prior written consent of the Company, 2. Under section 9  the Advisor may not assign the Agreement and the Company may assign it, 3 Under section 9 of the Undertaking the Company may assign the Undertaking.\\n']\n",
      "Similarity: 0.8800718188285828\n",
      "Sentence Pair: ['Who owns the IP? ', 'According to section 4 of the Undertaking (Appendix A), Any Work Product, upon creation, shall be fully and exclusively owned by the Company.\\n']\n",
      "Similarity: 0.6522742509841919\n",
      "Sentence Pair: ['Is there a non-compete obligation to the Advisor?', 'Yes. During the term of engagement with the Company and for a period of 12 months thereafter.\\n']\n",
      "Similarity: 0.8553465604782104\n",
      "Sentence Pair: ['Can the Advisor charge for meal time?', 'No. See Section 6.1, Billable Hour doesn’t include meals or travel time.  \\n']\n",
      "Similarity: 0.8360782265663147\n",
      "Sentence Pair: ['In which street does the Advisor live?', '1 Rabin st, Tel Aviv, Israel \\n']\n",
      "Similarity: 0.6478458642959595\n",
      "Sentence Pair: ['Is the Advisor entitled to social benefits? ', 'No. According to section 8 of the Agreement, the Advisor is an independent consultant and shall not be entitled to any overtime pay, insurance, paid vacation, severance payments or similar fringe or employment benefits from the Company.\\n']\n",
      "Similarity: 0.7954747080802917\n",
      "Sentence Pair: ['What happens if the Advisor claims compensation based on employment relationship with the Company? ', 'If the Advisor is determined to be an employee of the Company by a governmental authority, payments to the Advisor will be retroactively reduced so that 60% constitutes salary payments and 40% constitutes payment for statutory rights and benefits. The Company may offset any amounts due to the Advisor from any amounts payable under the Agreement. The Advisor must indemnify the Company for any losses or expenses incurred if an employer/employee relationship is determined to exist.\\n\\t \\n\\n']\n",
      "Similarity: 0.8959609270095825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def create_sentence_pairs(df, question_col, answer_col, model_name=\"nlpaueb/legal-bert-base-uncased\"):\n",
    "    \"\"\"\n",
    "    Creates sentence pairs (question, answer) from a DataFrame, calculates embeddings, and similarities.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the questions and answers.\n",
    "        question_col: The name of the column containing the questions.\n",
    "        answer_col: The name of the column containing the answers.\n",
    "        model_name: The name of the SentenceTransformer model to use (default is a legal-domain model).\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, each containing a sentence pair (question, answer), their embeddings, and similarity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Initialize a list to store the sentence pairs, embeddings, and similarities\n",
    "    sentence_pairs_with_data = []\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        question = row[question_col]\n",
    "        answer = row[answer_col]\n",
    "\n",
    "        # Create the sentence pair\n",
    "        sentence_pair = [question, answer]\n",
    "\n",
    "        # Calculate embeddings for the sentence pair\n",
    "        embeddings = model.encode(sentence_pair)\n",
    "\n",
    "        # Calculate cosine similarity between question and answer embeddings\n",
    "        similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))\n",
    "\n",
    "        # Append the sentence pair, embeddings, and similarity to the list\n",
    "        sentence_pairs_with_data.append((sentence_pair, embeddings, similarity))\n",
    "\n",
    "    return sentence_pairs_with_data\n",
    "\n",
    "# Example Usage:\n",
    "# df = pd.DataFrame({\n",
    "#     \"question\": [\"Who are the parties to the Agreement?\", \"What is the termination notice period?\"],\n",
    "#     \"answer\": [\"Cloud Investments Ltd. and Jack Robinson\", \"30 days\"]\n",
    "# })\n",
    "\n",
    "sentence_pairs_with_data = create_sentence_pairs(df, \"question\", \"ground_truths\")\n",
    "\n",
    "# Print the results\n",
    "for pair, embeddings, similarity in sentence_pairs_with_data:\n",
    "    print(f\"Sentence Pair: {pair}\")\n",
    "    # print(f\"Embeddings: {embeddings}\")\n",
    "    print(f\"Similarity: {similarity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.embeddings_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity  \u001b[38;5;66;03m# Use cosine_similarity directly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_sentence_pairs_with_openai\u001b[39m(df, question_col, answer_col, openai_api_key, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Creates sentence pairs (question, answer) from a DataFrame, calculates OpenAI embeddings, and similarities.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        A list of tuples, each containing a sentence pair (question, answer), their embeddings, and similarity.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.embeddings_utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "def create_sentence_pairs_with_openai(df, question_col, answer_col, openai_api_key, engine=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Creates sentence pairs (question, answer) from a DataFrame, calculates OpenAI embeddings, and similarities.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the questions and answers.\n",
    "        question_col: The name of the column containing the questions.\n",
    "        answer_col: The name of the column containing the answers.\n",
    "        openai_api_key: Your OpenAI API key.\n",
    "        engine: The OpenAI embedding engine to use (default is \"text-embedding-ada-002\").\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, each containing a sentence pair (question, answer), their embeddings, and similarity.\n",
    "    \"\"\"\n",
    "\n",
    "    # openai.api_key = openai_api_key  # Set your OpenAI API key\n",
    "\n",
    "    sentence_pairs_with_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question = row[question_col]\n",
    "        answer = row[answer_col]\n",
    "\n",
    "        sentence_pair = [question, answer]\n",
    "\n",
    "        # Calculate OpenAI embeddings for the sentence pair\n",
    "        question_embedding = get_embedding(question, engine=engine)\n",
    "        answer_embedding = get_embedding(answer, engine=engine)\n",
    "        embeddings = [question_embedding, answer_embedding]\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(question_embedding, answer_embedding)\n",
    "\n",
    "        sentence_pairs_with_data.append((sentence_pair, embeddings, similarity))\n",
    "\n",
    "    return sentence_pairs_with_data\n",
    "\n",
    "# Example Usage:\n",
    "df = pd.DataFrame({\n",
    "    \"question\": [\"Who are the parties to the Agreement?\", \"What is the termination notice period?\"],\n",
    "    \"answer\": [\"Cloud Investments Ltd. and Jack Robinson\", \"30 days\"]\n",
    "})\n",
    "\n",
    "# openai_api_key = \"YOUR_API_KEY\"  # Replace with your actual API key\n",
    "sentence_pairs_with_data = create_sentence_pairs_with_openai(df, \"question\", \"answer\", openai_api_key)\n",
    "\n",
    "# Print the results\n",
    "for pair, embeddings, similarity in sentence_pairs_with_data:\n",
    "    print(f\"Sentence Pair: {pair}\")\n",
    "    print(f\"Embeddings: {embeddings}\")\n",
    "    print(f\"Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenaAi embeddings similarity between quiz and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  Who are the parties to the Agreement and what ...   \n",
      "1                    What is the termination notice?   \n",
      "2  What are the payments to the Advisor under the...   \n",
      "3  Can the Agreement or any of its obligations be...   \n",
      "4                                  Who owns the IP?    \n",
      "5  Is there a non-compete obligation to the Advisor?   \n",
      "6              Can the Advisor charge for meal time?   \n",
      "7             In which street does the Advisor live?   \n",
      "8       Is the Advisor entitled to social benefits?    \n",
      "9  What happens if the Advisor claims compensatio...   \n",
      "\n",
      "                                       ground_truths  \\\n",
      "0  Cloud Investments Ltd. (“Company”) and Jack Ro...   \n",
      "1  According to section 4:14 days for convenience...   \n",
      "2  According to section 6: 1. Fees of $9 per hour...   \n",
      "3  1. Under section 1.1 the Advisor can’t assign ...   \n",
      "4  According to section 4 of the Undertaking (App...   \n",
      "5  Yes. During the term of engagement with the Co...   \n",
      "6  No. See Section 6.1, Billable Hour doesn’t inc...   \n",
      "7                    1 Rabin st, Tel Aviv, Israel \\n   \n",
      "8  No. According to section 8 of the Agreement, t...   \n",
      "9  If the Advisor is determined to be an employee...   \n",
      "\n",
      "                       similarity  \n",
      "0   {'score': 0.2501513318262547}  \n",
      "1  {'score': 0.19208414198358137}  \n",
      "2   {'score': 0.2104098934196964}  \n",
      "3   {'score': 0.1300368282064418}  \n",
      "4  {'score': 0.20552617067311607}  \n",
      "5  {'score': 0.19299571891633538}  \n",
      "6  {'score': 0.16587065158316516}  \n",
      "7  {'score': 0.22718675225529927}  \n",
      "8   {'score': 0.1384272995125343}  \n",
      "9  {'score': 0.10625257210459116}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "def evaluate_similarity_with_openai(df, question_col, answer_col, engine=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Evaluates the similarity between question and answer pairs in a DataFrame using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the questions and answers.\n",
    "        question_col: The name of the column containing the questions.\n",
    "        answer_col: The name of the column containing the answers.\n",
    "        openai_api_key: Your OpenAI API key.\n",
    "        engine: The OpenAI embedding engine to use (default is \"text-embedding-ada-002\").\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with the original question and answer pairs, along with their similarity scores.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Load the evaluator\n",
    "    evaluator = load_evaluator(\"pairwise_embedding_distance\", embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    questions = []\n",
    "    answers = []\n",
    "    similarities = []\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        question = row[question_col]\n",
    "        answer = row[answer_col]\n",
    "\n",
    "        # Evaluate similarity using OpenAI embeddings\n",
    "        similarity = evaluator.evaluate_string_pairs(prediction=question, prediction_b=answer)\n",
    "\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Create a new DataFrame with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        question_col: questions,\n",
    "        answer_col: answers,\n",
    "        \"similarity\": similarities\n",
    "    })\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Example Usage:\n",
    "# df = pd.DataFrame({\n",
    "#     \"question\": [\"Who are the parties to the Agreement?\", \"What is the termination notice period?\"],\n",
    "#     \"answer\": [\"Cloud Investments Ltd. and Jack Robinson\", \"30 days\"]\n",
    "# })\n",
    "\n",
    "results_df = evaluate_similarity_with_openai(df, \"question\", \"ground_truths\")\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hilla/code/10Academy-training/week11/contract-qa-high-precision-rag/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name nlpaueb/bert-base-uncased-contracts. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  Who are the parties to the Agreement and what ...   \n",
      "1                    What is the termination notice?   \n",
      "2  What are the payments to the Advisor under the...   \n",
      "3  Can the Agreement or any of its obligations be...   \n",
      "4                                  Who owns the IP?    \n",
      "5  Is there a non-compete obligation to the Advisor?   \n",
      "6              Can the Advisor charge for meal time?   \n",
      "7             In which street does the Advisor live?   \n",
      "8       Is the Advisor entitled to social benefits?    \n",
      "9  What happens if the Advisor claims compensatio...   \n",
      "\n",
      "                                       ground_truths  \\\n",
      "0  Cloud Investments Ltd. (“Company”) and Jack Ro...   \n",
      "1  According to section 4:14 days for convenience...   \n",
      "2  According to section 6: 1. Fees of $9 per hour...   \n",
      "3  1. Under section 1.1 the Advisor can’t assign ...   \n",
      "4  According to section 4 of the Undertaking (App...   \n",
      "5  Yes. During the term of engagement with the Co...   \n",
      "6  No. See Section 6.1, Billable Hour doesn’t inc...   \n",
      "7                    1 Rabin st, Tel Aviv, Israel \\n   \n",
      "8  No. According to section 8 of the Agreement, t...   \n",
      "9  If the Advisor is determined to be an employee...   \n",
      "\n",
      "  nlpaueb/legal-bert-base-uncased nlpaueb/bert-base-uncased-contracts  \\\n",
      "0                        0.805057                            0.666909   \n",
      "1                        0.706909                            0.670519   \n",
      "2                        0.827538                            0.733528   \n",
      "3                        0.880072                            0.750457   \n",
      "4                        0.652274                            0.632743   \n",
      "5                        0.855347                            0.765293   \n",
      "6                        0.836078                            0.822903   \n",
      "7                        0.647846                            0.443334   \n",
      "8                        0.795475                            0.803347   \n",
      "9                        0.895961                            0.849476   \n",
      "\n",
      "  all-mpnet-base-v2 all-MiniLM-L6-v2  \n",
      "0           0.38807         0.228614  \n",
      "1          0.396023         0.579316  \n",
      "2          0.472258         0.278494  \n",
      "3          0.606704         0.688757  \n",
      "4          0.464422         0.336257  \n",
      "5           0.34934         0.277722  \n",
      "6          0.547077         0.575612  \n",
      "7          0.488274         0.193531  \n",
      "8          0.616123         0.641111  \n",
      "9          0.760593         0.710087  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def create_sentence_pairs_multiple_models(df, question_col, answer_col, model_names):\n",
    "    \"\"\"\n",
    "    Creates sentence pairs and calculates similarities using multiple SentenceTransformer models.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the questions and answers.\n",
    "        question_col: The name of the column containing the questions.\n",
    "        answer_col: The name of the column containing the answers.\n",
    "        model_names: A list of SentenceTransformer model names to use.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with questions, answers, and similarity scores for each model.\n",
    "    \"\"\"\n",
    "\n",
    "    results = pd.DataFrame(columns=[question_col, answer_col] + model_names)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question = row[question_col]\n",
    "        answer = row[answer_col]\n",
    "\n",
    "        sentence_pair = [question, answer]\n",
    "        results.loc[index, question_col] = question\n",
    "        results.loc[index, answer_col] = answer\n",
    "\n",
    "        for model_name in model_names:\n",
    "            model = SentenceTransformer(model_name)\n",
    "            embeddings = model.encode(sentence_pair)\n",
    "            similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))\n",
    "            results.loc[index, model_name] = similarity\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example Usage:\n",
    "# df = pd.DataFrame({\n",
    "#     \"question\": [\"Who are the parties to the Agreement?\", \"What is the termination notice period?\"],\n",
    "#     \"answer\": [\"Cloud Investments Ltd. and Jack Robinson\", \"30 days\"]\n",
    "# })\n",
    "\n",
    "model_names = [\"nlpaueb/legal-bert-base-uncased\", \"nlpaueb/bert-base-uncased-contracts\", \"all-mpnet-base-v2\", \"all-MiniLM-L6-v2\"]  # Add more models as needed\n",
    "results_df = create_sentence_pairs_multiple_models(df, \"question\", \"ground_truths\", model_names)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
